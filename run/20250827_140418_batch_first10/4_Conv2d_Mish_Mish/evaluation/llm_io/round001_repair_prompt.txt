You are a senior CUDA-extension developer.
Your job is to **FIX** the compilation or runtime errors in the Python script
shown below.

OUTPUT RULES (STRICT) ────────────────────────────────────────────────
1. Inside the block, follow **exactly** this order:
   1. Imports – `torch`, `torch.nn`, `load_inline`.
   2. `source` – triple‑quoted CUDA string(s) (kernel + host wrapper).
   3. `cpp_src` – prototypes for *all* kernels you expose.
   4. **One** `load_inline` call per kernel group.
   5. `class ModelNew(nn.Module)` – mirrors original inputs/outputs but calls
      your CUDA kernels.
2. **Do NOT include** testing code, `if __name__ == "__main__"`, or extra prose.

────────────────────────────────────────
ERROR LOG
────────────────────────────────────────
Traceback (most recent call last):
  File "/home/wan00559/pipleline/utils/compile_and_run.py", line 536, in compare_and_bench
    diff = (test_out - ref_out).abs()
            ~~~~~~~~~^~~~~~~~~
RuntimeError: The size of tensor a (128) must match the size of tensor b (126) at non-singleton dimension 3

────────────────────────────────────────
OLD CODE (read-only)
────────────────────────────────────────
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# -------------------------------------------------------------------------------
# Inline CUDA kernel that fuses two consecutive Mish activations into one pass
#     y = mish(mish(x))   where mish(z) = z * tanh(softplus(z))
# -------------------------------------------------------------------------------
cuda_src = r"""
#include <torch/extension.h>
#include <cuda_runtime.h>
#include <cmath>

// ---------------------------------------------
// Numerically–stable Softplus implementation
// ---------------------------------------------
template <typename scalar_t>
__device__ __forceinline__ scalar_t softplus(const scalar_t x)
{
    const scalar_t threshold = static_cast<scalar_t>(20.0);
    if (x > threshold)         return x;                       // log(1+e^x) ~= x
    else if (x < -threshold)   return expf(x);                 // log(1+e^x) ~= e^x
    else                       return log1pf(expf(x));         // stable log(1+e^x)
}

// ---------------------------------------------
// Mish activation:  x * tanh(softplus(x))
// ---------------------------------------------
template <typename scalar_t>
__device__ __forceinline__ scalar_t mish(const scalar_t x)
{
    return x * tanhf(softplus<scalar_t>(x));
}

// ---------------------------------------------
// Fused kernel: y = mish(mish(x))
// ---------------------------------------------
template <typename scalar_t>
__global__ void fused_double_mish_kernel(const scalar_t* __restrict__ inp,
                                         scalar_t* __restrict__ out,
                                         size_t N)
{
    const size_t idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < N)
    {
        scalar_t v = inp[idx];
        v = mish<scalar_t>(v);     // first Mish
        v = mish<scalar_t>(v);     // second Mish
        out[idx] = v;
    }
}

// ---------------------------------------------
// C++/CUDA launcher
// ---------------------------------------------
torch::Tensor fused_double_mish(torch::Tensor x)
{
    TORCH_CHECK(x.is_cuda(), "Input must be a CUDA tensor");
    TORCH_CHECK(x.scalar_type() == at::kFloat,
                "Only float32 tensors are currently supported");

    const auto N      = static_cast<size_t>(x.numel());
    const int  blocks = (N + 255) / 256;
    const int  threads= 256;

    auto y = torch::empty_like(x);

    fused_double_mish_kernel<float><<<blocks, threads>>>(
        x.data_ptr<float>(),
        y.data_ptr<float>(),
        N);

    return y;
}
"""

cpp_hdr = "torch::Tensor fused_double_mish(torch::Tensor x);"

# Compile the CUDA extension (done at first import – cached afterwards)
fused_ext = load_inline(
    name="fused_double_mish_ext",
    cpp_sources=cpp_hdr,
    cuda_sources=cuda_src,
    functions=["fused_double_mish"],
    verbose=False,
)


# -------------------------------------------------------------------------------
# Optimised model leveraging the fused double-Mish CUDA kernel
# -------------------------------------------------------------------------------
class ModelNew(nn.Module):
    """
    Conv2d  ➔  fused mish(mish(·))
    """
    def __init__(self, in_channels, out_channels, kernel_size):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)
        self._mish = fused_ext  # holds the compiled CUDA op

    def forward(self, x):
        x = self.conv(x)
        x = self._mish.fused_double_mish(x)
        return x


# -------------------------------------------------------------------------------
# Helper functions (kept identical to the original file signature)
# -------------------------------------------------------------------------------
batch_size   = 32
in_channels  = 32
out_channels = 64
height = width = 128
kernel_size = 3

def get_inputs():
    return [torch.rand(batch_size, in_channels, height, width, device="cuda")]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size]

────────────────────────────────────────
Main Critical Problem
────────────────────────────────────────
critical_issue: Conv2d uses padding=1 instead of 0
why_it_matters: Extra padding keeps spatial dims at 128x128, while reference shrinks to 126x126, causing shape mismatch and wrong outputs.
minimal_fix_hint: remove padding argument (padding=0)

```python
# <your corrected code>
```
# ==========================================================
