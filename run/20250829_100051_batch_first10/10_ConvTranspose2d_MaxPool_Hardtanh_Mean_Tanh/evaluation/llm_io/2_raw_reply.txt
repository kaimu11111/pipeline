```python
# <complete ModelNew code>
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# ----------------------------------------------------------------------
# CUDA kernel + host wrapper
# ----------------------------------------------------------------------
source = r"""
#include <torch/extension.h>
#include <cuda_runtime.h>
#include <math.h>

// ---------------------------------------------------------------------
// Utility: fast intra-warp reduction (sum)
// ---------------------------------------------------------------------
__inline__ __device__
float warp_reduce_sum(float val) {
    #pragma unroll
    for (int offset = 16; offset > 0; offset >>= 1)
        val += __shfl_down_sync(0xffffffff, val, offset);
    return val;
}

////////////////////////////////////////////////////////////////////////////////
// Fused kernel: (MaxPool2d k=2,s=2) → HardTanh → Mean → Tanh
// One CUDA block  processes exactly one (n,c) channel map.
// We rely on warp-shuffle intrinsics to minimise shared-mem traffic.
// ---------------------------------------------------------------------------
////////////////////////////////////////////////////////////////////////////////
__global__ void fused_pool_hardtanh_mean_tanh_kernel(
        const float* __restrict__ x,   // [N, C, H, W]
        float* __restrict__ out,       // [N, C, 1, 1]
        const int N, const int C,
        const int H, const int W,
        const float hard_min,
        const float hard_max) {

    const int nc = blockIdx.x;                    // flat(n,c)
    if (nc >= N * C) return;

    const int n = nc / C;
    const int c = nc % C;

    const int pooled_H  = H >> 1;                 // H/2
    const int pooled_W  = W >> 1;                 // W/2
    const int pooled_sz = pooled_H * pooled_W;    // elements AFTER pooling

    // NCHW strides
    const int stride_n = C * H * W;
    const int stride_c = H * W;

    const int base_idx = n * stride_n + c * stride_c;

    // ------------------------------------------------------------------
    // Accumulate clamped-max over all 2×2 windows assigned to this (n,c)
    // ------------------------------------------------------------------
    float local_sum = 0.f;

    for (int idx = threadIdx.x; idx < pooled_sz; idx += blockDim.x) {
        const int ph = idx / pooled_W;            // pooled height
        const int pw = idx - ph * pooled_W;       // pooled width (faster than %)

        // Top-left corner of 2×2 window in original feature map
        const int h0 = ph << 1;
        const int w0 = pw << 1;
        const int h1 = h0 + 1;
        const int w1 = w0 + 1;

        const int row0 = base_idx + h0 * W;
        const int row1 = base_idx + h1 * W;

        // Read 4 values – memory-coalesced along W dimension
        float v00 = x[row0 + w0];
        float v01 = x[row0 + w1];
        float v10 = x[row1 + w0];
        float v11 = x[row1 + w1];

        // MaxPool 2×2
        float max_val = fmaxf(fmaxf(v00, v01), fmaxf(v10, v11));

        // HardTanh
        float clamped = fminf(fmaxf(max_val, hard_min), hard_max);

        local_sum += clamped;
    }

    // ------------------------------------------------------------------
    // Block-wide reduction – first within warps via shuffle, then across
    // warps through a tiny shared buffer (≤8 floats for 256-thread block).
    // ------------------------------------------------------------------
    const int lane    = threadIdx.x & 31;         // thread’s lane id
    const int warp_id = threadIdx.x >> 5;         // warp id inside block

    float warp_sum = warp_reduce_sum(local_sum);

    // Shared memory to collect one partial per warp
    extern __shared__ float sdata[];
    if (lane == 0) sdata[warp_id] = warp_sum;
    __syncthreads();

    // Final reduction by first warp
    float block_sum = 0.f;
    if (warp_id == 0) {
        block_sum = (lane < (blockDim.x >> 5)) ? sdata[lane] : 0.f;
        block_sum = warp_reduce_sum(block_sum);

        if (lane == 0) {
            float mean_val = block_sum / static_cast<float>(pooled_sz);
            out[nc] = tanhf(mean_val);
        }
    }
}

////////////////////////////////////////////////////////////////////////////////
// Host wrapper exposed to Python
////////////////////////////////////////////////////////////////////////////////
torch::Tensor fused_pool_hardtanh_mean_tanh_cuda(
        torch::Tensor input,
        float hard_min,
        float hard_max) {

    TORCH_CHECK(input.is_cuda(), "Input tensor must be on CUDA device");
    TORCH_CHECK(input.scalar_type() == at::kFloat,
                "Only float32 tensors are supported");
    TORCH_CHECK(input.dim() == 4, "Input must be a 4-D tensor [N,C,H,W]");
    TORCH_CHECK((input.size(2) & 1) == 0 && (input.size(3) & 1) == 0,
                "H and W must be even for 2×2 pooling");

    const int N = input.size(0);
    const int C = input.size(1);
    const int H = input.size(2);
    const int W = input.size(3);

    auto out = torch::empty({N, C, 1, 1}, input.options());

    // Tunable launch parameters
    constexpr int threads = 256;                  // 8 warps / block
    const int blocks      = N * C;
    const int sh_mem      = (threads >> 5) * sizeof(float); // one float / warp

    fused_pool_hardtanh_mean_tanh_kernel<<<blocks, threads, sh_mem>>>(
        input.data_ptr<float>(),
        out.data_ptr<float>(),
        N, C, H, W,
        hard_min,
        hard_max);

    return out;
}
"""

# ----------------------------------------------------------------------
# C++ prototypes exposed to Python
# ----------------------------------------------------------------------
cpp_src = """
torch::Tensor fused_pool_hardtanh_mean_tanh_cuda(torch::Tensor input,
                                                 float hard_min,
                                                 float hard_max);
"""

# ----------------------------------------------------------------------
# Build / load the extension
# ----------------------------------------------------------------------
fused_ops = load_inline(
    name="fused_pool_hardtanh_mean_tanh",
    cpp_sources=cpp_src,
    cuda_sources=source,
    functions=["fused_pool_hardtanh_mean_tanh_cuda"],
    verbose=False,
)

# ----------------------------------------------------------------------
# PyTorch module using the improved fused kernel
# ----------------------------------------------------------------------
class ModelNew(nn.Module):
    """
    Model with ConvTranspose2d followed by a highly-optimised fused
    (MaxPool2d → HardTanh → Mean → Tanh) CUDA kernel.
    The Python interface mirrors the original architecture.
    """
    def __init__(self,
                 in_channels,
                 out_channels,
                 kernel_size,
                 stride,
                 padding,
                 maxpool_kernel_size,
                 maxpool_stride,
                 hardtanh_min,
                 hardtanh_max):
        super().__init__()

        self.conv_transpose = nn.ConvTranspose2d(
            in_channels,
            out_channels,
            kernel_size=kernel_size,
            stride=stride,
            padding=padding,
        )

        self.hardtanh_min = float(hardtanh_min)
        self.hardtanh_max = float(hardtanh_max)

    def forward(self, x):
        # 1. Standard ConvTranspose2d
        x = self.conv_transpose(x)

        # 2-5. Fused CUDA kernel
        x = fused_ops.fused_pool_hardtanh_mean_tanh_cuda(
            x,
            self.hardtanh_min,
            self.hardtanh_max,
        )
        return x
```