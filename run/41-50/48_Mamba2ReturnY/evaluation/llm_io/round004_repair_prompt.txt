You are a senior CUDA-extension developer.
Your job is to **FIX** the compilation or runtime errors in the Python script
shown below.

OUTPUT RULES (STRICT) ────────────────────────────────────────────────
1. Inside the block, follow **exactly** this order:
   1. Imports – `torch`, `torch.nn`, `load_inline`.
   2. `source` – triple‑quoted CUDA string(s) (kernel + host wrapper).
   3. `cpp_src` – prototypes for *all* kernels you expose.
   4. **One** `load_inline` call per kernel group.
   5. `class ModelNew(nn.Module)` – mirrors original inputs/outputs but calls
      your CUDA kernels.
2. **Do NOT include** testing code, `if __name__ == "__main__"`, or extra prose.

────────────────────────────────────────
ERROR LOG
────────────────────────────────────────
Traceback (most recent call last):
  File "/home/wan00559/pipleline/utils/compile_and_run.py", line 541, in compare_and_bench
    raise ValueError(
ValueError: Outputs are not close (atol=0.001, rtol=0.001). max_abs_err=9.427e+09, mean_abs_err=1.230e+05

────────────────────────────────────────
OLD CODE (read-only)
────────────────────────────────────────
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

source = r"""
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

/* Exclusive segment-sum:
     S_{i,j} = Σ_{k=j}^{i-1} A_k    (0 ≤ j ≤ i < L)
   The diagonal therefore evaluates to exp(0)=1. */
__global__ void segsum_exp_kernel(const float* __restrict__ A,
                                  float* __restrict__ L,
                                  const int Llen)
{
    const int bhc          = blockIdx.x;                // flat (b,h,c) index
    const float* A_ptr     = A + (size_t)bhc * Llen;    // 1-D sequence start
    float*       L_ptr     = L + (size_t)bhc * Llen * Llen;

    const int tid          = threadIdx.x;
    const int n_threads    = blockDim.x;
    const int total_elems  = Llen * Llen;

    for (int idx = tid; idx < total_elems; idx += n_threads)
    {
        const int i = idx / Llen;          // row
        const int j = idx - i * Llen;      // column

        float val = 0.f;
        if (j <= i)                       // lower-triangular (incl. diagonal)
        {
            float acc = 0.f;
            #pragma unroll
            for (int k = j; k < i; ++k)   // EXCLUSIVE – stop at i-1
                acc += A_ptr[k];
            val = __expf(acc);            // exp(0)=1 for diagonal
        }
        L_ptr[idx] = val;                 // upper-triangular stays 0
    }
}

torch::Tensor segsum_exp_cuda(torch::Tensor A)
{
    TORCH_CHECK(A.dim() == 4, "Expected A of shape (B,H,C,L)");
    TORCH_CHECK(A.is_cuda(), "A must be on CUDA");
    TORCH_CHECK(A.scalar_type() == at::kFloat, "Only float32 supported");

    auto A_contig = A.contiguous();
    const int B = A_contig.size(0);
    const int H = A_contig.size(1);
    const int C = A_contig.size(2);
    const int L = A_contig.size(3);

    auto opts = torch::TensorOptions().dtype(A.dtype()).device(A.device());
    auto out  = torch::zeros({B, H, C, L, L}, opts);

    const int grid  = B * H * C;
    const int block = 256;
    segsum_exp_kernel<<<grid, block>>>(
        A_contig.data_ptr<float>(),
        out.data_ptr<float>(),
        L);

    return out;
}
"""

cpp_src = "torch::Tensor segsum_exp_cuda(torch::Tensor A);"

segsum_exp = load_inline(
    name        = "segsum_exp",
    cpp_sources = cpp_src,
    cuda_sources= source,
    functions   = ["segsum_exp_cuda"],
    verbose     = False,
)

class ModelNew(nn.Module):
    def __init__(self, batch_size, seq_length, n_heads, d_head, d_state, block_len=64):
        super().__init__()
        assert seq_length % block_len == 0, "seq_len must be divisible by block_len"

        self.batch_size = batch_size
        self.seq_length = seq_length
        self.n_heads    = n_heads
        self.d_head     = d_head
        self.d_state    = d_state
        self.block_len  = block_len

        # parameters copied from baseline
        self.A = nn.Parameter(torch.randn(batch_size, seq_length, n_heads))
        self.B = nn.Parameter(torch.randn(batch_size, seq_length, n_heads, d_state))
        self.C = nn.Parameter(torch.randn(batch_size, seq_length, n_heads, d_state))

        self._segsum_exp = segsum_exp.segsum_exp_cuda

    # exclusive CPU reference
    @staticmethod
    def _segsum_ref(x: torch.Tensor) -> torch.Tensor:
        T       = x.size(-1)
        cumsum  = torch.cumsum(x, dim=-1)
        shifted = nn.functional.pad(cumsum, (1, 0))[..., :-1]        # shift right
        segsum  = cumsum[..., :, None] - shifted[..., None, :]       # inclusive
        segsum  = segsum - torch.diag_embed(x)                       # make exclusive
        mask    = torch.tril(torch.ones(T, T, dtype=torch.bool, device=x.device))
        segsum  = segsum.masked_fill(~mask, float("-inf"))
        return segsum

    # reshape helpers
    def _blockify(self, t: torch.Tensor) -> torch.Tensor:
        b, s = t.shape[:2]
        c    = s // self.block_len
        return t.view(b, c, self.block_len, *t.shape[2:])

    def forward(self, X, initial_states=None):
        # ── blockify ────────────────────────────────────────────────
        X_blk = self._blockify(X)
        A_blk = self._blockify(self.A)
        B_blk = self._blockify(self.B)
        C_blk = self._blockify(self.C)

        # (b,h,c,l) for kernel
        A_blk_k = A_blk.permute(0, 3, 1, 2)

        # ── 1. diagonal block via CUDA ─────────────────────────────
        L     = self._segsum_exp(A_blk_k)                                # (b h c l l)
        Y_dig = torch.einsum("bclhn,bcshn,bhcls,bcshp->bclhp",
                             C_blk, B_blk, L, X_blk)

        # ── 2. intra-chunk state update ────────────────────────────
        A_cumsum    = torch.cumsum(A_blk_k, dim=-1)
        decay_state = torch.exp(A_cumsum[..., :, -1:] - A_cumsum)
        states      = torch.einsum("bclhn,bhcl,bclhp->bchpn",
                                   B_blk, decay_state, X_blk)

        # ── 3. inter-chunk recurrence ──────────────────────────────
        if initial_states is None:
            initial_states = torch.zeros_like(states[:, :1])
        states = torch.cat([initial_states, states], dim=1)

        decay_chunk = torch.exp(self._segsum_ref(
            nn.functional.pad(A_cumsum[..., -1], (1, 0))
        ))
        new_states  = torch.einsum("bhzc,bchpn->bzhpn", decay_chunk, states)
        states      = new_states[:, :-1]

        # ── 4. state-to-output conversion ──────────────────────────
        state_decay = torch.exp(A_cumsum)
        Y_off       = torch.einsum("bclhn,bchpn,bhcl->bclhp",
                                   C_blk, states, state_decay)

        # ── restore original shape ─────────────────────────────────
        Y_tot = Y_dig + Y_off
        b, c, l, h, p = Y_tot.shape
        return Y_tot.reshape(b, c * l, h, p)

────────────────────────────────────────
Main Critical Problem
────────────────────────────────────────
critical_issue: segsum_exp off-by-one: sums j..i-1, should sum j+1..i
why_it_matters: Each weight L[b,h,c,i,j] is shifted by one element (uses A_j instead of A_i), propagating wrong exponents and exploding output errors (~1e9).
minimal_fix_hint: change loop to for(int k=j+1;k<=i;++k)

```python
# <your corrected code>
```
# ==========================================================
