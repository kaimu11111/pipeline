You are a senior CUDA-extension developer.
Your job is to **FIX** the compilation or runtime errors in the Python script
shown below.

OUTPUT RULES (STRICT) ────────────────────────────────────────────────
1. Inside the block, follow **exactly** this order:
   1. Imports – `torch`, `torch.nn`, `load_inline`.
   2. `source` – triple‑quoted CUDA string(s) (kernel + host wrapper).
   3. `cpp_src` – prototypes for *all* kernels you expose.
   4. **One** `load_inline` call per kernel group.
   5. `class ModelNew(nn.Module)` – mirrors original inputs/outputs but calls
      your CUDA kernels.
2. **Do NOT include** testing code, `if __name__ == "__main__"`, or extra prose.

────────────────────────────────────────
ERROR LOG
────────────────────────────────────────
/home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Error building extension 'window_ops': [1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=window_ops -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/window_ops/main.cpp -o main.o 
[2/3] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=window_ops -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/window_ops/cuda.cu -o cuda.cuda.o 
[3/3] c++ main.o cuda.cuda.o -shared -L/home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/lib64 -lcudart -o window_ops.so
FAILED: window_ops.so 
c++ main.o cuda.cuda.o -shared -L/home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/lib64 -lcudart -o window_ops.so
/usr/bin/ld: cuda.cuda.o: in function `PyInit_window_ops':
tmpxft_00024204_00000000-6_cuda.cudafe1.cpp:(.text+0x9f5): multiple definition of `PyInit_window_ops'; main.o:main.cpp:(.text+0x257): first defined here
collect2: error: ld returned 1 exit status
ninja: build stopped: subcommand failed.

────────────────────────────────────────
OLD CODE (read-only)
────────────────────────────────────────
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline
from itertools import repeat
import collections.abc

# ----------------------------------------------------------------------
#                       CUDA KERNELS (INLINE BUILD)
# ----------------------------------------------------------------------
cpp_source = r"""
#include <torch/extension.h>

torch::Tensor window_partition_cuda(torch::Tensor x, int window_size);
torch::Tensor window_reverse_cuda(torch::Tensor windows, int window_size,
                                  int H, int W);
"""

cuda_source = r"""
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

#define CHECK_CUDA(x) TORCH_CHECK(x.is_cuda(), #x " must be a CUDA tensor")
#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x " must be contiguous")
#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)

using index_t = long long;

namespace {

__global__ void window_partition_kernel(
    const float* __restrict__ input,
    float* __restrict__ output,
    const int B, const int H, const int W, const int C,
    const int window_size,
    const int num_windows_per_img)
{
    index_t total = static_cast<index_t>(B) * num_windows_per_img *
                    window_size * window_size * C;
    index_t idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= total) return;

    int c             = idx % C;
    idx              /= C;
    int win_x_in      = idx % window_size;
    idx              /= window_size;
    int win_y_in      = idx % window_size;
    idx              /= window_size;
    int win_idx_glb   = idx;                 // [0 .. B*num_windows_per_img)

    int b             = win_idx_glb / num_windows_per_img;
    int win_local     = win_idx_glb % num_windows_per_img;

    int num_windows_w = W / window_size;
    int win_y         = win_local / num_windows_w;
    int win_x         = win_local % num_windows_w;

    int in_y          = win_y * window_size + win_y_in;
    int in_x          = win_x * window_size + win_x_in;

    index_t in_offset  = (((static_cast<index_t>(b) * H + in_y) * W + in_x) * C) + c;
    index_t out_offset = (((static_cast<index_t>(win_idx_glb) * window_size + win_y_in)
                           * window_size + win_x_in) * C) + c;

    output[out_offset] = input[in_offset];
}

__global__ void window_reverse_kernel(
    const float* __restrict__ input,
    float* __restrict__ output,
    const int B, const int H, const int W, const int C,
    const int window_size,
    const int num_windows_per_img)
{
    index_t total = static_cast<index_t>(B) * H * W * C;
    index_t idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= total) return;

    int c = idx % C;
    idx   /= C;
    int x = idx % W;
    idx   /= W;
    int y = idx % H;
    idx   /= H;
    int b = idx;

    int num_windows_w = W / window_size;
    int win_y         = y / window_size;
    int win_x         = x / window_size;
    int win_idx_glb   = b * num_windows_per_img + win_y * num_windows_w + win_x;

    int y_in          = y % window_size;
    int x_in          = x % window_size;

    index_t in_offset  = (((static_cast<index_t>(win_idx_glb) * window_size + y_in)
                           * window_size + x_in) * C) + c;
    index_t out_offset = (((static_cast<index_t>(b) * H + y) * W + x) * C) + c;

    output[out_offset] = input[in_offset];
}

} // anonymous namespace

torch::Tensor window_partition_cuda(torch::Tensor x, int window_size)
{
    CHECK_INPUT(x);
    TORCH_CHECK(x.dim() == 4, "Input must be 4D (B, H, W, C)");

    const int B = x.size(0);
    const int H = x.size(1);
    const int W = x.size(2);
    const int C = x.size(3);

    TORCH_CHECK(H % window_size == 0 && W % window_size == 0,
                "H and W must be divisible by window_size");

    const int num_windows_h = H / window_size;
    const int num_windows_w = W / window_size;
    const int num_windows_per_img = num_windows_h * num_windows_w;

    auto out = torch::empty({B * num_windows_per_img,
                             window_size, window_size, C},
                             x.options());

    index_t total = static_cast<index_t>(B) * num_windows_per_img *
                    window_size * window_size * C;
    const int threads = 256;
    const int blocks  = (total + threads - 1) / threads;

    window_partition_kernel<<<blocks, threads>>>(
        x.data_ptr<float>(), out.data_ptr<float>(),
        B, H, W, C, window_size, num_windows_per_img);

    return out;
}

torch::Tensor window_reverse_cuda(torch::Tensor windows, int window_size,
                                  int H, int W)
{
    CHECK_INPUT(windows);
    TORCH_CHECK(windows.dim() == 4,
                "windows must be 4D (B*nW, window, window, C)");

    const int C = windows.size(3);
    const int num_windows_per_img = (H / window_size) * (W / window_size);
    const int total_windows       = windows.size(0);
    const int B                   = total_windows / num_windows_per_img;

    auto out = torch::empty({B, H, W, C}, windows.options());

    index_t total = static_cast<index_t>(B) * H * W * C;
    const int threads = 256;
    const int blocks  = (total + threads - 1) / threads;

    window_reverse_kernel<<<blocks, threads>>>(
        windows.data_ptr<float>(), out.data_ptr<float>(),
        B, H, W, C, window_size, num_windows_per_img);

    return out;
}

PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
    m.def("window_partition_cuda", &window_partition_cuda,
          "Window Partition (CUDA)");
    m.def("window_reverse_cuda", &window_reverse_cuda,
          "Window Reverse (CUDA)");
}
"""

# Build & load the extension
window_ops = load_inline(
    name="window_ops",
    cpp_sources=cpp_source,
    cuda_sources=cuda_source,
    functions=["window_partition_cuda", "window_reverse_cuda"],
    verbose=False,
)

# ----------------------------------------------------------------------
#                       PYTHON WRAPPERS FOR CUDA OPS
# ----------------------------------------------------------------------
def window_partition_fast(x: torch.Tensor, window_size: int):
    return window_ops.window_partition_cuda(x.contiguous(), window_size)

def window_reverse_fast(windows: torch.Tensor, window_size: int, H: int, W: int):
    return window_ops.window_reverse_cuda(windows.contiguous(),
                                          window_size, H, W)

# ----------------------------------------------------------------------
#                         MODEL DEFINITIONS
# ----------------------------------------------------------------------
class Mlp(nn.Module):
    def __init__(self, in_features, hidden_features=None, out_features=None,
                 act_layer=nn.GELU, drop=0.):
        super().__init__()
        out_features   = out_features   or in_features
        hidden_features = hidden_features or in_features
        self.fc1  = nn.Linear(in_features, hidden_features)
        self.act  = act_layer()
        self.fc2  = nn.Linear(hidden_features, out_features)
        self.drop = nn.Dropout(drop)

    def forward(self, x):
        x = self.drop(self.act(self.fc1(x)))
        x = self.drop(self.fc2(x))
        return x


class SwinMLPBlock(nn.Module):
    """ Optimised Swin MLP Block using custom CUDA window ops """

    def __init__(self, dim, input_resolution, num_heads,
                 window_size=7, shift_size=0,
                 mlp_ratio=4., drop=0.,
                 drop_path=0., act_layer=nn.GELU,
                 norm_layer=nn.LayerNorm):
        super().__init__()
        self.dim              = dim
        self.input_resolution = input_resolution
        self.num_heads        = num_heads
        self.window_size      = window_size
        self.shift_size       = shift_size
        self.mlp_ratio        = mlp_ratio

        if min(self.input_resolution) <= self.window_size:
            self.shift_size  = 0
            self.window_size = min(self.input_resolution)

        assert 0 <= self.shift_size < self.window_size

        # paddings for shifted windows
        self.padding = [self.window_size - self.shift_size, self.shift_size,
                        self.window_size - self.shift_size, self.shift_size]

        self.norm1 = norm_layer(dim)
        self.spatial_mlp = nn.Conv1d(self.num_heads * self.window_size ** 2,
                                     self.num_heads * self.window_size ** 2,
                                     kernel_size=1, groups=self.num_heads)

        self.drop_path = nn.Identity()
        self.norm2 = norm_layer(dim)
        mlp_hidden_dim = int(dim * mlp_ratio)
        self.mlp = Mlp(in_features=dim,
                       hidden_features=mlp_hidden_dim,
                       act_layer=act_layer,
                       drop=drop)

    def forward(self, x):
        H, W   = self.input_resolution
        B, L, C= x.shape
        assert L == H * W, "input feature has wrong size"

        shortcut = x
        x = self.norm1(x).view(B, H, W, C)

        # cyclic shift
        if self.shift_size > 0:
            P_l, P_r, P_t, P_b = self.padding
            shifted_x = F.pad(x, [0, 0, P_l, P_r, P_t, P_b])
        else:
            shifted_x = x
        _, H_pad, W_pad, _ = shifted_x.shape

        # Window partition (CUDA)
        x_windows = window_partition_fast(shifted_x, self.window_size)   # (nW*B, ws, ws, C)
        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)

        # Spatial MLP
        x_wh = x_windows.view(-1, self.window_size * self.window_size,
                              self.num_heads, C // self.num_heads)
        x_wh = x_wh.transpose(1, 2)                             # (nW*B, nH, ws*ws, C//nH)
        x_wh = x_wh.reshape(-1, self.num_heads * self.window_size * self.window_size,
                            C // self.num_heads)
        x_wh = self.spatial_mlp(x_wh)                           # apply conv1d
        x_wh = x_wh.view(-1, self.num_heads, self.window_size * self.window_size,
                         C // self.num_heads).transpose(1, 2)
        spatial_mlp_windows = x_wh.reshape(-1,
                                           self.window_size * self.window_size, C)

        # merge windows
        spatial_mlp_windows = spatial_mlp_windows.view(-1,
                                                       self.window_size,
                                                       self.window_size, C)
        shifted_x = window_reverse_fast(spatial_mlp_windows, self.window_size,
                                        H_pad, W_pad)           # (B, H', W', C)

        # reverse cyclic shift
        if self.shift_size > 0:
            P_l, P_r, P_t, P_b = self.padding
            x = shifted_x[:, P_t:-P_b, P_l:-P_r, :].contiguous()
        else:
            x = shifted_x

        x = x.view(B, H * W, C)

        # FFN
        x = shortcut + self.drop_path(x)
        x = x + self.drop_path(self.mlp(self.norm2(x)))
        return x


class PatchMerging(nn.Module):
    """ Patch Merging Layer. """

    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):
        super().__init__()
        self.input_resolution = input_resolution
        self.dim = dim
        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)
        self.norm = norm_layer(4 * dim)

    def forward(self, x):
        H, W = self.input_resolution
        B, L, C = x.shape
        assert L == H * W and H % 2 == 0 and W % 2 == 0

        x = x.view(B, H, W, C)
        x0 = x[:, 0::2, 0::2, :]
        x1 = x[:, 1::2, 0::2, :]
        x2 = x[:, 0::2, 1::2, :]
        x3 = x[:, 1::2, 1::2, :]
        x = torch.cat([x0, x1, x2, x3], -1)      # B H/2 W/2 4*C
        x = x.view(B, -1, 4 * C)
        x = self.reduction(self.norm(x))
        return x


class BasicLayer(nn.Module):
    """ One Swin MLP stage. """

    def __init__(self, dim, input_resolution, depth, num_heads, window_size,
                 mlp_ratio=4., drop=0., drop_path=0.,
                 norm_layer=nn.LayerNorm, downsample=None):
        super().__init__()
        self.depth = depth

        self.blocks = nn.ModuleList([
            SwinMLPBlock(dim=dim, input_resolution=input_resolution,
                         num_heads=num_heads, window_size=window_size,
                         shift_size=0 if (i % 2 == 0) else window_size // 2,
                         mlp_ratio=mlp_ratio, drop=drop,
                         drop_path=drop_path[i] if isinstance(drop_path, list)
                         else drop_path, norm_layer=norm_layer)
            for i in range(depth)
        ])

        self.downsample = (downsample(input_resolution, dim, norm_layer)
                           if downsample is not None else None)

    def forward(self, x):
        for blk in self.blocks:
            x = blk(x)
        if self.downsample is not None:
            x = self.downsample(x)
        return x


def _ntuple(n):
    def parse(x):
        if isinstance(x, collections.abc.Iterable) and not isinstance(x, str):
            return tuple(x)
        return tuple(repeat(x, n))
    return parse
to_2tuple = _ntuple(2)


class PatchEmbed(nn.Module):
    """ Image to Patch Embedding """

    def __init__(self, img_size=224, patch_size=4, in_chans=3,
                 embed_dim=96, norm_layer=None):
        super().__init__()
        img_size   = to_2tuple(img_size)
        patch_size = to_2tuple(patch_size)
        self.img_size = img_size
        self.patch_size = patch_size
        self.num_patches = (img_size[0] // patch_size[0]) * \
                           (img_size[1] // patch_size[1])

        self.proj = nn.Conv2d(in_chans, embed_dim,
                              kernel_size=patch_size,
                              stride=patch_size)
        self.norm = norm_layer(embed_dim) if norm_layer else None

    def forward(self, x):
        B, C, H, W = x.shape
        assert (H, W) == self.img_size, \
            f"Input image size {H}*{W} != model {self.img_size}"
        x = self.proj(x).flatten(2).transpose(1, 2)  # B N C
        if self.norm:
            x = self.norm(x)
        return x


class ModelNew(nn.Module):
    """ Swin MLP with custom CUDA window ops """

    def __init__(self, img_size=224, patch_size=4, in_chans=3,
                 num_classes=1000, embed_dim=96, depths=(2, 2, 6, 2),
                 num_heads=(3, 6, 12, 24), window_size=7, mlp_ratio=4.,
                 drop_rate=0., drop_path_rate=0.1, norm_layer=nn.LayerNorm,
                 patch_norm=True):
        super().__init__()

        self.num_classes = num_classes
        self.num_layers  = len(depths)
        self.embed_dim   = embed_dim
        self.patch_norm  = patch_norm
        self.num_features= int(embed_dim * 2 ** (self.num_layers - 1))

        # Patch embedding -------------------------------------------------
        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size,
                                      in_chans=in_chans, embed_dim=embed_dim,
                                      norm_layer=norm_layer if patch_norm else None)
        patches_resolution = self.patch_embed.img_size[0] // patch_size, \
                             self.patch_embed.img_size[1] // patch_size
        self.patches_resolution = patches_resolution

        self.pos_drop = nn.Dropout(p=drop_rate)

        # stochastic depth
        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]

        # Build layers ----------------------------------------------------
        self.layers = nn.ModuleList()
        for i_layer in range(self.num_layers):
            layer = BasicLayer(dim=int(embed_dim * 2 ** i_layer),
                               input_resolution=(patches_resolution[0] // (2 ** i_layer),
                                                 patches_resolution[1] // (2 ** i_layer)),
                               depth=depths[i_layer],
                               num_heads=num_heads[i_layer],
                               window_size=window_size,
                               mlp_ratio=mlp_ratio,
                               drop=drop_rate,
                               drop_path=dpr[sum(depths[:i_layer]):
                                             sum(depths[:i_layer + 1])],
                               norm_layer=norm_layer,
                               downsample=PatchMerging if (i_layer <
                                                           self.num_layers - 1)
                               else None)
            self.layers.append(layer)

        self.norm   = norm_layer(self.num_features)
        self.avgpool= nn.AdaptiveAvgPool1d(1)
        self.head   = nn.Linear(self.num_features, num_classes) \
                      if num_classes > 0 else nn.Identity()

    # ------------------------------------------------------------------
    def forward_features(self, x):
        x = self.patch_embed(x)
        x = self.pos_drop(x)
        for layer in self.layers:
            x = layer(x)
        x = self.norm(x)                                 # B, L, C
        x = self.avgpool(x.transpose(1, 2)).squeeze(-1)  # B, C
        return x

    def forward(self, x):
        x = self.forward_features(x)
        x = self.head(x)
        return x


# ----------------------------------------------------------------------
# Helper functions for external scripts
# ----------------------------------------------------------------------
batch_size  = 5
image_size  = 112

def get_inputs():
    return [torch.rand(batch_size, 3, image_size, image_size).cuda()]

def get_init_inputs():
    return []

────────────────────────────────────────
Main Critical Problem
────────────────────────────────────────
critical_issue: cuda_source includes its own PYBIND11_MODULE
why_it_matters: load_inline auto-creates a module; the extra definition causes duplicate PyInit_window_ops symbol and compilation fails, so custom CUDA ops never run.
minimal_fix_hint: Delete PYBIND11_MODULE block in cuda_source

```python
# <your corrected code>
```
# ==========================================================
