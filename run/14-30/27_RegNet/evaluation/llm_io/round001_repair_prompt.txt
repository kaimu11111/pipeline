You are a senior CUDA-extension developer.
Your job is to **FIX** the compilation or runtime errors in the Python script
shown below.

OUTPUT RULES (STRICT) ────────────────────────────────────────────────
1. Inside the block, follow **exactly** this order:
   1. Imports – `torch`, `torch.nn`, `load_inline`.
   2. `source` – triple‑quoted CUDA string(s) (kernel + host wrapper).
   3. `cpp_src` – prototypes for *all* kernels you expose.
   4. **One** `load_inline` call per kernel group.
   5. `class ModelNew(nn.Module)` – mirrors original inputs/outputs but calls
      your CUDA kernels.
2. **Do NOT include** testing code, `if __name__ == "__main__"`, or extra prose.

────────────────────────────────────────
ERROR LOG
────────────────────────────────────────
Traceback (most recent call last):
  File "/home/wan00559/pipleline/utils/compile_and_run.py", line 541, in compare_and_bench
    raise ValueError(
ValueError: Outputs are not close (atol=0.001, rtol=0.001). max_abs_err=1.226e-02, mean_abs_err=5.420e-03

────────────────────────────────────────
OLD CODE (read-only)
────────────────────────────────────────
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# ------------------------------------------------------------------
# Inline CUDA kernels: fused Global Average Pooling and ReLU
# ------------------------------------------------------------------
cuda_src = r"""
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

#define CHECK_CUDA(x) TORCH_CHECK(x.is_cuda(), #x " must be a CUDA tensor")
#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x " must be contiguous")
#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)

// ---------------------------------------------
// Element-wise ReLU kernel
// ---------------------------------------------
__global__ void relu_kernel(const float* __restrict__ input,
                            float* __restrict__ output,
                            const int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float val = input[idx];
        output[idx] = val > 0.f ? val : 0.f;
    }
}

torch::Tensor relu_forward_cuda(torch::Tensor input) {
    CHECK_INPUT(input);
    auto output = torch::empty_like(input);
    const int size = input.numel();
    const int threads = 256;
    const int blocks  = (size + threads - 1) / threads;

    relu_kernel<<<blocks, threads>>>(input.data_ptr<float>(),
                                     output.data_ptr<float>(),
                                     size);
    return output;
}

// ---------------------------------------------
// Global Average Pooling kernel: (N, C, H, W) -> (N, C)
// ---------------------------------------------
__global__ void gap_kernel(const float* __restrict__ input,
                           float* __restrict__ output,
                           const int N, const int C,
                           const int H, const int W) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int NC  = N * C;
    if (idx < NC) {
        int n = idx / C;
        int c = idx % C;
        const float* in_ptr = input + ( (n * C + c) * H * W );
        float sum = 0.f;
        for (int i = 0; i < H * W; ++i) {
            sum += in_ptr[i];
        }
        output[n * C + c] = sum / (H * W);
    }
}

torch::Tensor global_avg_pool_forward_cuda(torch::Tensor input) {
    CHECK_INPUT(input);
    TORCH_CHECK(input.dim() == 4, "Input must be 4-D (N, C, H, W)");

    const int N = input.size(0);
    const int C = input.size(1);
    const int H = input.size(2);
    const int W = input.size(3);

    auto output = torch::empty({N, C}, input.options());
    const int threads = 256;
    const int blocks  = (N * C + threads - 1) / threads;

    gap_kernel<<<blocks, threads>>>(input.data_ptr<float>(),
                                    output.data_ptr<float>(),
                                    N, C, H, W);
    return output;
}
"""

cpp_src = """
torch::Tensor relu_forward_cuda(torch::Tensor input);
torch::Tensor global_avg_pool_forward_cuda(torch::Tensor input);
"""

# Compile the extension
custom_ops = load_inline(
    name="custom_ops",
    cpp_sources=cpp_src,
    cuda_sources=cuda_src,
    functions=["relu_forward_cuda", "global_avg_pool_forward_cuda"],
    verbose=False,
)

# ------------------------------------------------------------------
# Wrapper modules to call the custom CUDA kernels from PyTorch
# ------------------------------------------------------------------
class CustomReLU(nn.Module):
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return custom_ops.relu_forward_cuda(x.contiguous())

class GlobalAvgPool2d(nn.Module):
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return custom_ops.global_avg_pool_forward_cuda(x.contiguous())

# ------------------------------------------------------------------
# Optimised model definition
# ------------------------------------------------------------------
class ModelNew(nn.Module):
    def __init__(self, input_channels, stages, block_widths, output_classes):
        super().__init__()
        self.stages = stages
        self.block_widths = block_widths

        layers = []
        current_channels = input_channels
        for i in range(stages):
            layers.append(self._make_stage(current_channels, block_widths[i]))
            current_channels = block_widths[i]

        self.feature_extractor = nn.Sequential(*layers)
        self.global_pool = GlobalAvgPool2d()
        self.fc = nn.Linear(block_widths[-1], output_classes)

    def _make_stage(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            CustomReLU(),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            CustomReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )

    def forward(self, x):
        x = self.feature_extractor(x)
        x = self.global_pool(x)   # (N, C)
        x = self.fc(x)
        return x

# ------------------------------------------------------------------
# Utility functions required by the evaluation harness
# ------------------------------------------------------------------
batch_size = 4
input_channels = 3
image_height, image_width = 56, 56
stages = 3
block_widths = [32, 64, 128]
output_classes = 10

def get_inputs():
    """Generates random input tensor."""
    return [torch.rand(batch_size, input_channels, image_height, image_width).cuda()]

def get_init_inputs():
    """Initialises ModelNew parameters."""
    return [input_channels, stages, block_widths, output_classes]

────────────────────────────────────────
Main Critical Problem
────────────────────────────────────────
critical_issue: Conv2d layers created with bias=False
why_it_matters: Reference model includes convolution biases; their removal alters activations (especially with BatchNorm in eval mode), producing divergent outputs.
minimal_fix_hint: set bias=True on both Conv2d layers

```python
# <your corrected code>
```
# ==========================================================
