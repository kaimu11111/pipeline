You are given:

ERROR_LOG:
Traceback (most recent call last):
  File "/home/wan00559/pipleline/utils/compile_and_run.py", line 541, in compare_and_bench
    raise ValueError(
ValueError: Outputs are not close (atol=0.001, rtol=0.001). max_abs_err=2.894e+01, mean_abs_err=3.604e-01

PyTorch reference (ground truth):

import torch
import torch.nn as nn

class Model(nn.Module):
    """
    Model that performs a batch matrix multiplication, instance normalization, summation, residual addition, and multiplication.
    """
    def __init__(self, in_features, out_features, eps=1e-5, momentum=0.1):
        super(Model, self).__init__()
        self.bmm = nn.Linear(in_features, out_features)
        self.instance_norm = nn.InstanceNorm2d(out_features, eps=eps, momentum=momentum)

    def forward(self, x, y):
        """
        Args:
            x (torch.Tensor): Input tensor of shape (batch_size, in_features).
            y (torch.Tensor): Input tensor of shape (batch_size, out_features).

        Returns:
            torch.Tensor: Output tensor of shape (batch_size, out_features).
        """
        x = self.bmm(x)
        x = self.instance_norm(x.unsqueeze(1).unsqueeze(1)).squeeze(1).squeeze(1)
        x = x + y
        x = x * y
        return x

batch_size = 512  # Increased batch size
in_features = 4096  # Increased input features
out_features = 4096  # Increased output features

def get_inputs():
    return [torch.rand(batch_size, in_features), torch.rand(batch_size, out_features)]

def get_init_inputs():
    return [in_features, out_features]

CUDA candidate (to audit):

import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline


source = r"""
#include <cuda.h>
#include <cuda_runtime.h>
#include <torch/extension.h>

/* -------------------------------------------------------------------------
   Kernel: fused_kernel
   1) Instance-normalise per (batch, channel) over remaining dims
   2) out = (norm(x) + y) * y
   ------------------------------------------------------------------------- */
__global__ void fused_kernel(const float* __restrict__ x,
                             const float* __restrict__ y,
                             float*       __restrict__ out,
                             const int64_t C,
                             const int64_t S,
                             const float   eps)
{
    extern __shared__ float sdata[];
    float* s_sum    = sdata;               // [blockDim.x]
    float* s_sum_sq = sdata + blockDim.x;  // [blockDim.x]

    const int  n   = blockIdx.y;   // batch index
    const int  c   = blockIdx.x;   // channel index
    const int  tid = threadIdx.x;
    const int  T   = blockDim.x;

    const int64_t base = (static_cast<int64_t>(n) * C + c) * S;

    /* ----------------------- compute mean / variance -------------------- */
    float local_sum    = 0.f;
    float local_sum_sq = 0.f;

    for (int64_t s = tid; s < S; s += T) {
        const float v = x[base + s];
        local_sum    += v;
        local_sum_sq += v * v;
    }
    s_sum[tid]    = local_sum;
    s_sum_sq[tid] = local_sum_sq;
    __syncthreads();

    for (int off = T >> 1; off > 0; off >>= 1) {
        if (tid < off) {
            s_sum[tid]    += s_sum[tid + off];
            s_sum_sq[tid] += s_sum_sq[tid + off];
        }
        __syncthreads();
    }

    const float mean   = s_sum[0] / static_cast<float>(S);
    const float var    = s_sum_sq[0] / static_cast<float>(S) - mean * mean;
    const float invStd = rsqrtf(var + eps);

    /* ----------------------- normalise + add + mul ---------------------- */
    for (int64_t s = tid; s < S; s += T) {
        const float xn   = (x[base + s] - mean) * invStd;
        const float valY = y[base + s];
        out[base + s]    = (xn + valY) * valY;
    }
}

/* --------------------------------------------------------------------- */
torch::Tensor fused_forward(torch::Tensor x,
                            torch::Tensor y,
                            const float   eps)
{
    TORCH_CHECK(x.is_cuda() && y.is_cuda(), "inputs must be CUDA tensors");
    TORCH_CHECK(x.dtype() == torch::kFloat32 && y.dtype() == torch::kFloat32,
                "inputs must be float32");
    TORCH_CHECK(x.sizes() == y.sizes(), "x and y must have identical shapes");

    x = x.contiguous();
    y = y.contiguous();

    const int64_t N = x.size(0);
    const int64_t C = x.size(1);
    /* --------- support arbitrary rank ≥2 (2-D, 3-D, 4-D …) ------------- */
    const int64_t S = x.numel() / (N * C);

    auto out = torch::empty_like(x);

    const int   threads = 256;
    const dim3  grid(static_cast<unsigned int>(C),
                     static_cast<unsigned int>(N));
    const size_t shmem = threads * sizeof(float) * 2;

    fused_kernel<<<grid, threads, shmem>>>(x.data_ptr<float>(),
                                           y.data_ptr<float>(),
                                           out.data_ptr<float>(),
                                           C, S, eps);

    return out;
}
"""

cpp_src = r"""
#include <torch/extension.h>
torch::Tensor fused_forward(torch::Tensor x,
                            torch::Tensor y,
                            const float   eps);
"""

_fused = load_inline(
    name="fused_instance_add_mul",
    cpp_sources=cpp_src,
    cuda_sources=source,
    functions=["fused_forward"],
    verbose=False,
)


class ModelNew(nn.Module):
    """
    Linear  ->  fused(instance_norm + add + mul)
    """
    def __init__(self, in_features, out_features, eps=1e-5):
        super().__init__()
        self.linear = nn.Linear(in_features, out_features, bias=True)
        self.eps = eps

    def forward(self, x, y):
        x = self.linear(x).contiguous().cuda()
        y = y.contiguous().cuda()
        return _fused.fused_forward(x, y, self.eps)


Follow the Rules and produce the JSON exactly in the specified format.